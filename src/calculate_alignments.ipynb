{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a3f9c2-6bfe-40ba-81ee-b76599d5bdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This remains here as a trophey of triumph over tribulation\n",
    "\"Â \" == \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29347a8b-f845-4098-b0ef-5f3457cdca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os.path\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "parentdir = os.getcwd()[:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876c9df-90fe-402d-a65b-b3b595ff43f8",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f012ca9-a0b5-4955-b47a-3624fbef0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection_of_words(m1, m2, targetWord, k):\n",
    "    '''\n",
    "    description:\n",
    "        Finds top k words from m1 that are in m2\n",
    "    '''\n",
    "    # retrieve k*searchFactor nearest words as candidates\n",
    "    searchFactor = 150 \n",
    "    if targetWord == \"village\":\n",
    "        output = m1.wv.most_similar(targetWord, topn=k*3000) # village is especially sparse\n",
    "    else:\n",
    "        output = m1.wv.most_similar(targetWord, topn=k*searchFactor)\n",
    "    candidate_words = [word for word,_ in output]\n",
    "    final_words = list()\n",
    "    \n",
    "    for word in candidate_words:\n",
    "        try:\n",
    "            # breaks if word not in m2\n",
    "            m2.wv[word]\n",
    "            if len(final_words) < k:\n",
    "                final_words.append(word)\n",
    "            else:\n",
    "                break\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if len(final_words) == k:\n",
    "        return final_words\n",
    "    else:\n",
    "        sys.exit(f\"Neighborhood too sparse for word: {targetWord}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594bdab4-1466-4333-b4bd-95755e2f9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_nearest_neighbors(m1, m2, targetWord, k):\n",
    "    '''\n",
    "    inputs:\n",
    "        m1: model the top k words will be derived from\n",
    "        m2: other model\n",
    "        targetWord: word from which top k words will be derived\n",
    "        k: number of words to compare\n",
    "        \n",
    "    output:\n",
    "        pearson correlation between the two datasets\n",
    "        difference in similarity between m1 and m2's average similarities to m1's k nearest neighbors\n",
    "        \n",
    "    description:\n",
    "        Returns the difference between the average similarity of the k most similar words to the \n",
    "        target word from m1 and the average similarity of the same words in m2.\n",
    "    '''\n",
    "    \n",
    "    # finds k most similar words in m1 that are in m2.\n",
    "    top_words = find_intersection_of_words(m1, m2, targetWord, k)\n",
    "\n",
    "    # stores similarities of top_words to target word\n",
    "    m1Similarities = list()\n",
    "    m2Similarities = list()\n",
    "    \n",
    "    m1TargetVec = m1.wv[targetWord]\n",
    "    m2TargetVec = m2.wv[targetWord]\n",
    "    # create list of similarities\n",
    "    for word in top_words:\n",
    "\n",
    "        m1ComparisonVec = m1.wv[word]\n",
    "        m1Similarity = 1 - spatial.distance.cosine(m1TargetVec, m1ComparisonVec)\n",
    "        m1Similarities.append(m1Similarity)\n",
    "        \n",
    "        m2ComparisonVec = m2.wv[word]\n",
    "        m2Similarity = 1 - spatial.distance.cosine(m2TargetVec, m2ComparisonVec)\n",
    "        m2Similarities.append(m2Similarity)\n",
    "        \n",
    "    # return (sum(m1Similarities) / len(m1Similarities)) - (sum(m2Similarities) / len(m2Similarities))\n",
    "    corr, p_value = pearsonr(m1Similarities, m2Similarities)\n",
    "    # if p_value > 0.1:\n",
    "    #     print(f\"p-value is: {p_value} for {targetWord}\")\n",
    "    return corr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0199c7-f012-4a8c-835e-82d815ee39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_a_domain(m1, m2, wordList, k):\n",
    "    '''\n",
    "    description:\n",
    "        Calculates the average pearson correlation values of words in a domain as well as the standard deviation.\n",
    "        \n",
    "        NOTE: Function is for testing/debugging purposes only.\n",
    "    '''\n",
    "    similarities = list()\n",
    "    for word in wordList:\n",
    "        wordComparison = (compare_nearest_neighbors(m1, m2, word, k) + compare_nearest_neighbors(m2, m1, word, k)) / 2\n",
    "        similarities.append(wordComparison)\n",
    "\n",
    "    data = pd.Series(similarities)\n",
    "     \n",
    "    return  f\"Mean difference: {round(data.mean(), 4)}     Standard Deviation: {round(data.std(), 4)}\"\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a50323-972b-4d1b-ad36-2f130195134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_domains(m1, m2, k, domains_dict):\n",
    "    '''\n",
    "    description:\n",
    "        Calculates the average and standard deviation of alignment of words across domains.\n",
    "    input:\n",
    "        m1: one of two models. Order doesn't matter\n",
    "        m2: second of two models. Order doesn't matter\n",
    "        k: how many nearest words to compare when calculating alignment of single word\n",
    "        domains_dict: keys are domain names, values are lists of words of that domain\n",
    "    output:\n",
    "        dataframe containing alignment statistics across domains\n",
    "    '''\n",
    "    results = {\"Domain\": [], \"Alignment\": [], \"Standard Deviation\": []}\n",
    "    domains = list(domains_dict.keys())\n",
    "    alignments = []\n",
    "    std = []\n",
    "    for domain in domains:\n",
    "        wordList = domains_dict[domain]\n",
    "        similarities = list()\n",
    "        for word in wordList:\n",
    "            wordComparison = (compare_nearest_neighbors(m1, m2, word, k) + compare_nearest_neighbors(m2, m1, word, k)) / 2\n",
    "            similarities.append(wordComparison)\n",
    "\n",
    "        data = pd.Series(similarities)\n",
    "        \n",
    "        alignments.append(round(data.mean(), 4))\n",
    "        std.append(round(data.std(), 4))\n",
    "        \n",
    "    return pd.DataFrame({\"Domain\" : domains, \"Alignments\": alignments, \"Standard Deviation\": std})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c592d-5cc8-46cf-b84c-aa4e1106e54d",
   "metadata": {},
   "source": [
    "### Load and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd75d1f-c646-464a-ac1c-c2d8f1ad6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# domains.json includes all domain words that exist in both datasets\n",
    "with open(os.path.join(parentdir, \"data\", \"domains.json\"), \"rt\") as f:\n",
    "    domains = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efbc915a-2898-422a-a67c-43523ce6cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec.load(os.path.join(parentdir, \"models\", \"NANTeC_clean.bin\"))\n",
    "model2 = Word2Vec.load(os.path.join(parentdir, \"models\", \"indicorp_clean.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df5ba8a5-d2ad-4e64-a5fd-b6fca8815989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Alignments</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quantity</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.2143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kinship</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Possession</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.1702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Speech and language</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>0.1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Miscellaneous function words</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.2298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cognition</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Motion</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basic actions and technology</td>\n",
       "      <td>0.3298</td>\n",
       "      <td>0.1771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Modern world</td>\n",
       "      <td>0.3239</td>\n",
       "      <td>0.1570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Spatial relations</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Social and political relations</td>\n",
       "      <td>0.3213</td>\n",
       "      <td>0.1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emotions and values</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sense perception</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The body</td>\n",
       "      <td>0.2537</td>\n",
       "      <td>0.1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The house</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>0.1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clothing and grooming</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The physical world</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Food and drink</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animals</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agriculture and vegetation</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.1273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Domain  Alignments  Standard Deviation\n",
       "12                        Quantity      0.6105              0.2143\n",
       "7                          Kinship      0.4674              0.1253\n",
       "20                            Time      0.4639              0.1415\n",
       "11                      Possession      0.4264              0.1702\n",
       "16             Speech and language      0.4031              0.1314\n",
       "8     Miscellaneous function words      0.3931              0.2298\n",
       "4                        Cognition      0.3787              0.1267\n",
       "10                          Motion      0.3520              0.1603\n",
       "2     Basic actions and technology      0.3298              0.1771\n",
       "9                     Modern world      0.3239              0.1570\n",
       "15               Spatial relations      0.3235              0.1635\n",
       "14  Social and political relations      0.3213              0.1514\n",
       "5              Emotions and values      0.2737              0.1824\n",
       "13                Sense perception      0.2573              0.1467\n",
       "17                        The body      0.2537              0.1415\n",
       "18                       The house      0.2439              0.1281\n",
       "3            Clothing and grooming      0.2414              0.1325\n",
       "19              The physical world      0.2400              0.1465\n",
       "6                   Food and drink      0.1908              0.1179\n",
       "1                          Animals      0.1681              0.1230\n",
       "0       Agriculture and vegetation      0.1133              0.1273"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = how many nearest words to compare when calculating alignment of single word\n",
    "k = 100\n",
    "# run code\n",
    "results = compare_all_domains(model1, model2, 100, domains)\n",
    "results = results.sort_values(by=['Alignments'], ascending=False, ignore_index=True)\n",
    "# write code to results\n",
    "with open(os.path.join(parentdir, \"results\", f\"results_{k}.csv\"), \"wt\") as f:\n",
    "    results.to_csv(f)\n",
    "# display results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b540ae1-953f-41a3-bd65-25903078ab40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
